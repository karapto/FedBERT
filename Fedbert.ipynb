{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P3_note\bbook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karapto/FF4BERT/blob/main/P3_note%08book.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc6U5qZZIWMO"
      },
      "source": [
        "##Loading the final dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ylg_3uhplH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5c1230-79a9-4cb7-d700-4b0802cf4e2f"
      },
      "source": [
        "!pip install wget\n",
        "import tarfile\n",
        "import os\n",
        "import wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKjWXKs5v73O"
      },
      "source": [
        "#experiment_code\n",
        "wget.download('https://archive.org/download/wikiner_dataset_csv.tar/wikiner_dataset_txt.tar.gz')\n",
        "tar = tarfile.open('wikiner_dataset_txt.tar.gz', mode='r')\n",
        "tar.extractall('./dataset_txt')\n",
        "tar.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU7pqJpXkjtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5131a09f-e5be-4524-b96f-685c066d4a08"
      },
      "source": [
        "import sys\n",
        "# !pip install syft\n",
        "!git clone \"https://github.com/karapto/PySyft.git\"\n",
        "!cd PySyft && pip install -e .\n",
        "!cd /content/PySyft/packages/syft/ &&  python setup.py install\n",
        "sys.path.append(\"PySyft\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'PySyft' already exists and is not an empty directory.\n",
            "\u001b[31mERROR: File \"setup.py\" not found. Directory cannot be installed in editable mode: /content/PySyft\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'author-email' will not be supported in future versions. Please use the underscore name 'author_email' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'long-description' will not be supported in future versions. Please use the underscore name 'long_description' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'long-description-content-type' will not be supported in future versions. Please use the underscore name 'long_description_content_type' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'project-urls' will not be supported in future versions. Please use the underscore name 'project_urls' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/lib/python3.7/distutils/dist.py:274: UserWarning: Unknown distribution option: 'use_scm_version'\n",
            "  warnings.warn(msg)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing src/syft.egg-info/PKG-INFO\n",
            "writing dependency_links to src/syft.egg-info/dependency_links.txt\n",
            "writing entry points to src/syft.egg-info/entry_points.txt\n",
            "writing requirements to src/syft.egg-info/requires.txt\n",
            "writing top-level names to src/syft.egg-info/top_level.txt\n",
            "package init file 'src/syft/img/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/grid/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/util/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/zksk/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/python/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/numpy/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/petlib/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/sympc/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/tenseal/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/statsmodels/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/sklearn/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/torch/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/pandas/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/lib/python/collections/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/grid/service/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/grid/messages/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/remote_dataloader/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/common/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/auth/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/node/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/pointer/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/store/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/io/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/plan/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/node/domain/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/node/common/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/node/domain/service/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/node/common/service/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/proto/core/node/common/action/__init__.py' not found (or not a regular file)\n",
            "package init file 'src/syft/grid/example_nodes/__init__.py' not found (or not a regular file)\n",
            "adding license file 'LICENSE'\n",
            "adding license file 'AUTHORS.rst'\n",
            "writing manifest file 'src/syft.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/img\n",
            "copying build/lib/syft/img/logo.png -> build/bdist.linux-x86_64/egg/syft/img\n",
            "copying build/lib/syft/img/logo_duet.png -> build/bdist.linux-x86_64/egg/syft/img\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/zksk\n",
            "copying build/lib/syft/proto/lib/zksk/secret_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/zksk\n",
            "copying build/lib/syft/proto/lib/zksk/nizk_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/zksk\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/slice_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/set_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/list_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/tuple_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/float_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/bool_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/python/collections\n",
            "copying build/lib/syft/proto/lib/python/collections/ordered_dict_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python/collections\n",
            "copying build/lib/syft/proto/lib/python/int_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/string_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/range_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/complex_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/none_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "copying build/lib/syft/proto/lib/python/dict_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/python\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/numpy\n",
            "copying build/lib/syft/proto/lib/numpy/array_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/numpy\n",
            "copying build/lib/syft/proto/lib/numpy/tensor_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/numpy\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/petlib\n",
            "copying build/lib/syft/proto/lib/petlib/ecpt_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/petlib\n",
            "copying build/lib/syft/proto/lib/petlib/bn_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/petlib\n",
            "copying build/lib/syft/proto/lib/petlib/ecpt_group_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/petlib\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/sympc\n",
            "copying build/lib/syft/proto/lib/sympc/share_tensor_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/sympc\n",
            "copying build/lib/syft/proto/lib/sympc/session_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/sympc\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/tenseal\n",
            "copying build/lib/syft/proto/lib/tenseal/vector_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/tenseal\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/statsmodels\n",
            "copying build/lib/syft/proto/lib/statsmodels/family_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/statsmodels\n",
            "copying build/lib/syft/proto/lib/statsmodels/results_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/statsmodels\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/sklearn\n",
            "copying build/lib/syft/proto/lib/sklearn/logistic_model_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/sklearn\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/torch\n",
            "copying build/lib/syft/proto/lib/torch/device_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/torch\n",
            "copying build/lib/syft/proto/lib/torch/module_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/torch\n",
            "copying build/lib/syft/proto/lib/torch/returntypes_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/torch\n",
            "copying build/lib/syft/proto/lib/torch/parameter_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/torch\n",
            "copying build/lib/syft/proto/lib/torch/tensor_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/lib/pandas\n",
            "copying build/lib/syft/proto/lib/pandas/categorical_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/pandas\n",
            "copying build/lib/syft/proto/lib/pandas/series_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/pandas\n",
            "copying build/lib/syft/proto/lib/pandas/frame_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/lib/pandas\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/grid\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/grid/service\n",
            "copying build/lib/syft/proto/grid/service/signaling_service_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/service\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/transfer_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/tensor_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/association_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/infra_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/user_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/role_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/network_search_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/dataset_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/setup_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/request_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "copying build/lib/syft/proto/grid/messages/group_messages_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/grid/messages\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/util\n",
            "copying build/lib/syft/proto/util/vendor_bytes_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/util\n",
            "copying build/lib/syft/proto/util/data_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/util\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/remote_dataloader\n",
            "copying build/lib/syft/proto/core/remote_dataloader/remote_dataset_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/remote_dataloader\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/common\n",
            "copying build/lib/syft/proto/core/common/common_object_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/common\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/auth\n",
            "copying build/lib/syft/proto/core/auth/signed_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/auth\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/node\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/node/domain\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service\n",
            "copying build/lib/syft/proto/core/node/domain/service/accept_or_deny_request_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service\n",
            "copying build/lib/syft/proto/core/node/domain/service/get_all_requests_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service\n",
            "copying build/lib/syft/proto/core/node/domain/service/request_answer_response_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service\n",
            "copying build/lib/syft/proto/core/node/domain/service/request_handler_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service\n",
            "copying build/lib/syft/proto/core/node/domain/service/request_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service\n",
            "copying build/lib/syft/proto/core/node/domain/service/request_answer_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/node/common\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "copying build/lib/syft/proto/core/node/common/service/object_search_permission_update_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "copying build/lib/syft/proto/core/node/common/service/get_repr_service_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "copying build/lib/syft/proto/core/node/common/service/resolve_pointer_type_service_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "copying build/lib/syft/proto/core/node/common/service/heritage_update_service_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "copying build/lib/syft/proto/core/node/common/service/repr_service_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "copying build/lib/syft/proto/core/node/common/service/object_search_message_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "copying build/lib/syft/proto/core/node/common/service/child_node_lifecycle_service_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/get_set_static_attribute_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/get_enum_attribute_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/run_class_method_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/save_object_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/garbage_collect_object_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/action_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/get_object_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/get_set_property_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/garbage_collect_batched_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/run_function_or_constructor_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/action/exception_action_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action\n",
            "copying build/lib/syft/proto/core/node/common/client_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common\n",
            "copying build/lib/syft/proto/core/node/common/metadata_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/node/common\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/pointer\n",
            "copying build/lib/syft/proto/core/pointer/pointer_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/pointer\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/store\n",
            "copying build/lib/syft/proto/core/store/dataset_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/store\n",
            "copying build/lib/syft/proto/core/store/store_object_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/store\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/io\n",
            "copying build/lib/syft/proto/core/io/address_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/io\n",
            "copying build/lib/syft/proto/core/io/location_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/io\n",
            "copying build/lib/syft/proto/core/io/connection_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/io\n",
            "copying build/lib/syft/proto/core/io/route_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/io\n",
            "creating build/bdist.linux-x86_64/egg/syft/proto/core/plan\n",
            "copying build/lib/syft/proto/core/plan/plan_pb2.py -> build/bdist.linux-x86_64/egg/syft/proto/core/plan\n",
            "copying build/lib/syft/generate_wrapper.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/openmined_psi\n",
            "copying build/lib/syft/lib/openmined_psi/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/openmined_psi\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/misc\n",
            "copying build/lib/syft/lib/misc/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/misc\n",
            "copying build/lib/syft/lib/misc/union.py -> build/bdist.linux-x86_64/egg/syft/lib/misc\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/pytorch_lightning\n",
            "copying build/lib/syft/lib/pytorch_lightning/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/pytorch_lightning\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/zksk\n",
            "copying build/lib/syft/lib/zksk/nizk.py -> build/bdist.linux-x86_64/egg/syft/lib/zksk\n",
            "copying build/lib/syft/lib/zksk/secret.py -> build/bdist.linux-x86_64/egg/syft/lib/zksk\n",
            "copying build/lib/syft/lib/zksk/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/zksk\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/remote_dataloader\n",
            "copying build/lib/syft/lib/remote_dataloader/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/remote_dataloader\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/bool.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/tuple.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/int.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/set.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/float.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/none.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/complex.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/string.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/primitive_factory.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/list.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/primitive_interface.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/python/collections\n",
            "copying build/lib/syft/lib/python/collections/ordered_dict.py -> build/bdist.linux-x86_64/egg/syft/lib/python/collections\n",
            "copying build/lib/syft/lib/python/collections/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/python/collections\n",
            "copying build/lib/syft/lib/python/dict.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/iterator.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/primitive_container.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/types.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/util.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/range.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "copying build/lib/syft/lib/python/slice.py -> build/bdist.linux-x86_64/egg/syft/lib/python\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/numpy\n",
            "copying build/lib/syft/lib/numpy/array.py -> build/bdist.linux-x86_64/egg/syft/lib/numpy\n",
            "copying build/lib/syft/lib/numpy/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/numpy\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/petlib\n",
            "copying build/lib/syft/lib/petlib/ecpt.py -> build/bdist.linux-x86_64/egg/syft/lib/petlib\n",
            "copying build/lib/syft/lib/petlib/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/petlib\n",
            "copying build/lib/syft/lib/petlib/ecpt_group.py -> build/bdist.linux-x86_64/egg/syft/lib/petlib\n",
            "copying build/lib/syft/lib/petlib/bn.py -> build/bdist.linux-x86_64/egg/syft/lib/petlib\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/sympc\n",
            "copying build/lib/syft/lib/sympc/session_util.py -> build/bdist.linux-x86_64/egg/syft/lib/sympc\n",
            "copying build/lib/syft/lib/sympc/share.py -> build/bdist.linux-x86_64/egg/syft/lib/sympc\n",
            "copying build/lib/syft/lib/sympc/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/sympc\n",
            "copying build/lib/syft/lib/sympc/session.py -> build/bdist.linux-x86_64/egg/syft/lib/sympc\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/tenseal\n",
            "copying build/lib/syft/lib/tenseal/plain_tensor.py -> build/bdist.linux-x86_64/egg/syft/lib/tenseal\n",
            "copying build/lib/syft/lib/tenseal/ckks_vector.py -> build/bdist.linux-x86_64/egg/syft/lib/tenseal\n",
            "copying build/lib/syft/lib/tenseal/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/tenseal\n",
            "copying build/lib/syft/lib/tenseal/context.py -> build/bdist.linux-x86_64/egg/syft/lib/tenseal\n",
            "copying build/lib/syft/lib/tenseal/bfv_vector.py -> build/bdist.linux-x86_64/egg/syft/lib/tenseal\n",
            "copying build/lib/syft/lib/tenseal/ckks_tensor.py -> build/bdist.linux-x86_64/egg/syft/lib/tenseal\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/torchvision\n",
            "copying build/lib/syft/lib/torchvision/allowlist.py -> build/bdist.linux-x86_64/egg/syft/lib/torchvision\n",
            "copying build/lib/syft/lib/torchvision/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/torchvision\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/PIL\n",
            "copying build/lib/syft/lib/PIL/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/PIL\n",
            "copying build/lib/syft/lib/PIL/image.py -> build/bdist.linux-x86_64/egg/syft/lib/PIL\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/xgboost\n",
            "copying build/lib/syft/lib/xgboost/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/xgboost\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/pydp\n",
            "copying build/lib/syft/lib/pydp/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/pydp\n",
            "copying build/lib/syft/lib/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/statsmodels\n",
            "copying build/lib/syft/lib/statsmodels/results.py -> build/bdist.linux-x86_64/egg/syft/lib/statsmodels\n",
            "copying build/lib/syft/lib/statsmodels/family.py -> build/bdist.linux-x86_64/egg/syft/lib/statsmodels\n",
            "copying build/lib/syft/lib/statsmodels/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/statsmodels\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/opacus\n",
            "copying build/lib/syft/lib/opacus/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/opacus\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/tensor\n",
            "copying build/lib/syft/lib/tensor/tensorbase_util.py -> build/bdist.linux-x86_64/egg/syft/lib/tensor\n",
            "copying build/lib/syft/lib/tensor/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/tensor\n",
            "copying build/lib/syft/lib/tensor/tensorbase.py -> build/bdist.linux-x86_64/egg/syft/lib/tensor\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/gym\n",
            "copying build/lib/syft/lib/gym/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/gym\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/sklearn\n",
            "copying build/lib/syft/lib/sklearn/serializing_models.py -> build/bdist.linux-x86_64/egg/syft/lib/sklearn\n",
            "copying build/lib/syft/lib/sklearn/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/sklearn\n",
            "copying build/lib/syft/lib/util.py -> build/bdist.linux-x86_64/egg/syft/lib\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/uppercase_tensor.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/parameter.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/module.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/device.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/allowlist.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/return_types.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "copying build/lib/syft/lib/torch/tensor_util.py -> build/bdist.linux-x86_64/egg/syft/lib/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/pandas\n",
            "copying build/lib/syft/lib/pandas/series.py -> build/bdist.linux-x86_64/egg/syft/lib/pandas\n",
            "copying build/lib/syft/lib/pandas/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/pandas\n",
            "copying build/lib/syft/lib/pandas/categorical_dtype.py -> build/bdist.linux-x86_64/egg/syft/lib/pandas\n",
            "copying build/lib/syft/lib/pandas/categorical.py -> build/bdist.linux-x86_64/egg/syft/lib/pandas\n",
            "copying build/lib/syft/lib/pandas/frame.py -> build/bdist.linux-x86_64/egg/syft/lib/pandas\n",
            "creating build/bdist.linux-x86_64/egg/syft/lib/plan\n",
            "copying build/lib/syft/lib/plan/__init__.py -> build/bdist.linux-x86_64/egg/syft/lib/plan\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid/services\n",
            "copying build/lib/syft/grid/services/__init__.py -> build/bdist.linux-x86_64/egg/syft/grid/services\n",
            "copying build/lib/syft/grid/services/signaling_service.py -> build/bdist.linux-x86_64/egg/syft/grid/services\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid/example_nodes\n",
            "copying build/lib/syft/grid/example_nodes/network.py -> build/bdist.linux-x86_64/egg/syft/grid/example_nodes\n",
            "copying build/lib/syft/grid/example_nodes/pks.py -> build/bdist.linux-x86_64/egg/syft/grid/example_nodes\n",
            "copying build/lib/syft/grid/example_nodes/device.py -> build/bdist.linux-x86_64/egg/syft/grid/example_nodes\n",
            "copying build/lib/syft/grid/example_nodes/domain.py -> build/bdist.linux-x86_64/egg/syft/grid/example_nodes\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid/connections\n",
            "copying build/lib/syft/grid/connections/webrtc.py -> build/bdist.linux-x86_64/egg/syft/grid/connections\n",
            "copying build/lib/syft/grid/connections/http_connection.py -> build/bdist.linux-x86_64/egg/syft/grid/connections\n",
            "copying build/lib/syft/grid/connections/__init__.py -> build/bdist.linux-x86_64/egg/syft/grid/connections\n",
            "copying build/lib/syft/grid/__init__.py -> build/bdist.linux-x86_64/egg/syft/grid\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid/client\n",
            "copying build/lib/syft/grid/client/exceptions.py -> build/bdist.linux-x86_64/egg/syft/grid/client\n",
            "copying build/lib/syft/grid/client/client.py -> build/bdist.linux-x86_64/egg/syft/grid/client\n",
            "copying build/lib/syft/grid/client/grid_connection.py -> build/bdist.linux-x86_64/egg/syft/grid/client\n",
            "copying build/lib/syft/grid/client/enums.py -> build/bdist.linux-x86_64/egg/syft/grid/client\n",
            "copying build/lib/syft/grid/client/__init__.py -> build/bdist.linux-x86_64/egg/syft/grid/client\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/role_api.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/dataset_api.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/worker_api.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/group_api.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/__init__.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/request_api.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/user_api.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "copying build/lib/syft/grid/client/request_api/association_api.py -> build/bdist.linux-x86_64/egg/syft/grid/client/request_api\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/infra_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/association_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/dataset_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/group_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/tensor_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/network_search_message.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/request_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/transfer_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/role_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/__init__.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/setup_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "copying build/lib/syft/grid/messages/user_messages.py -> build/bdist.linux-x86_64/egg/syft/grid/messages\n",
            "creating build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/grid/duet/bcolors.py -> build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/grid/duet/signaling_client.py -> build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/grid/duet/webrtc_duet.py -> build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/grid/duet/exchange_ids.py -> build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/grid/duet/__init__.py -> build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/grid/duet/om_signaling_client.py -> build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/grid/duet/ui.py -> build/bdist.linux-x86_64/egg/syft/grid/duet\n",
            "copying build/lib/syft/logger.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/__init__.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/core\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/remote_dataloader\n",
            "copying build/lib/syft/core/remote_dataloader/remote_dataloader.py -> build/bdist.linux-x86_64/egg/syft/core/remote_dataloader\n",
            "copying build/lib/syft/core/remote_dataloader/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/remote_dataloader\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/object.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/group.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/environment.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/uid.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/message.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/event_loop.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/common/serde\n",
            "copying build/lib/syft/core/common/serde/serializable.py -> build/bdist.linux-x86_64/egg/syft/core/common/serde\n",
            "copying build/lib/syft/core/common/serde/deserialize.py -> build/bdist.linux-x86_64/egg/syft/core/common/serde\n",
            "copying build/lib/syft/core/common/serde/serialize.py -> build/bdist.linux-x86_64/egg/syft/core/common/serde\n",
            "copying build/lib/syft/core/common/serde/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/common/serde\n",
            "copying build/lib/syft/core/common/pointer.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "copying build/lib/syft/core/common/storeable_object.py -> build/bdist.linux-x86_64/egg/syft/core/common\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/domain\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/service/request_answer_message.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/service/request_message.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/service/vm_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/service/get_all_requests_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/service/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/service/request_handler_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/service/accept_or_deny_request_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain/service\n",
            "copying build/lib/syft/core/node/domain/client.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain\n",
            "copying build/lib/syft/core/node/domain/domain.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain\n",
            "copying build/lib/syft/core/node/domain/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/domain\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/pki\n",
            "copying build/lib/syft/core/node/pki/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/pki\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/device\n",
            "copying build/lib/syft/core/node/device/device.py -> build/bdist.linux-x86_64/egg/syft/core/node/device\n",
            "copying build/lib/syft/core/node/device/client.py -> build/bdist.linux-x86_64/egg/syft/core/node/device\n",
            "copying build/lib/syft/core/node/device/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/device\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/device/device_type\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs\n",
            "copying build/lib/syft/core/node/device/device_type/specs/network.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs\n",
            "copying build/lib/syft/core/node/device/device_type/specs/storage.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs\n",
            "copying build/lib/syft/core/node/device/device_type/specs/provider.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs\n",
            "copying build/lib/syft/core/node/device/device_type/specs/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs\n",
            "copying build/lib/syft/core/node/device/device_type/specs/gpu.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs\n",
            "copying build/lib/syft/core/node/device/device_type/specs/cpu.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs\n",
            "copying build/lib/syft/core/node/device/device_type/unknown.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type\n",
            "copying build/lib/syft/core/node/device/device_type/device_type.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type\n",
            "copying build/lib/syft/core/node/device/device_type/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/device/device_type\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/common\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/obj_action_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/child_node_lifecycle_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/resolve_pointer_type_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/msg_forwarding_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/obj_search_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/heritage_update_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/node_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/auth.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/get_repr_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/repr_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/obj_search_permission_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "copying build/lib/syft/core/node/common/service/solve_pointer_type_service.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/service\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/get_or_set_static_attribute_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/exception_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/get_or_set_property_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/common.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/run_class_method_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/save_object_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/garbage_collect_batched_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/function_or_constructor_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/get_object_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/garbage_collect_object_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/action/get_enum_attribute_action.py -> build/bdist.linux-x86_64/egg/syft/core/node/common/action\n",
            "copying build/lib/syft/core/node/common/client.py -> build/bdist.linux-x86_64/egg/syft/core/node/common\n",
            "copying build/lib/syft/core/node/common/metadata.py -> build/bdist.linux-x86_64/egg/syft/core/node/common\n",
            "copying build/lib/syft/core/node/common/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/common\n",
            "copying build/lib/syft/core/node/common/node.py -> build/bdist.linux-x86_64/egg/syft/core/node/common\n",
            "copying build/lib/syft/core/node/common/util.py -> build/bdist.linux-x86_64/egg/syft/core/node/common\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/vm\n",
            "copying build/lib/syft/core/node/vm/vm.py -> build/bdist.linux-x86_64/egg/syft/core/node/vm\n",
            "copying build/lib/syft/core/node/vm/client.py -> build/bdist.linux-x86_64/egg/syft/core/node/vm\n",
            "copying build/lib/syft/core/node/vm/plan_vm.py -> build/bdist.linux-x86_64/egg/syft/core/node/vm\n",
            "copying build/lib/syft/core/node/vm/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/vm\n",
            "copying build/lib/syft/core/node/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/abstract\n",
            "copying build/lib/syft/core/node/abstract/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/abstract\n",
            "copying build/lib/syft/core/node/abstract/node.py -> build/bdist.linux-x86_64/egg/syft/core/node/abstract\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/node/network\n",
            "copying build/lib/syft/core/node/network/network.py -> build/bdist.linux-x86_64/egg/syft/core/node/network\n",
            "copying build/lib/syft/core/node/network/client.py -> build/bdist.linux-x86_64/egg/syft/core/node/network\n",
            "copying build/lib/syft/core/node/network/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/node/network\n",
            "copying build/lib/syft/core/__init__.py -> build/bdist.linux-x86_64/egg/syft/core\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/pointer\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection\n",
            "copying build/lib/syft/core/pointer/garbage_collection/gc_batched.py -> build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection\n",
            "copying build/lib/syft/core/pointer/garbage_collection/gc_strategy.py -> build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection\n",
            "copying build/lib/syft/core/pointer/garbage_collection/gc_simple.py -> build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection\n",
            "copying build/lib/syft/core/pointer/garbage_collection/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection\n",
            "copying build/lib/syft/core/pointer/garbage_collection/garbage_collection.py -> build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection\n",
            "copying build/lib/syft/core/pointer/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/pointer\n",
            "copying build/lib/syft/core/pointer/pointer.py -> build/bdist.linux-x86_64/egg/syft/core/pointer\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/store\n",
            "copying build/lib/syft/core/store/store_interface.py -> build/bdist.linux-x86_64/egg/syft/core/store\n",
            "copying build/lib/syft/core/store/store_memory.py -> build/bdist.linux-x86_64/egg/syft/core/store\n",
            "copying build/lib/syft/core/store/dataset.py -> build/bdist.linux-x86_64/egg/syft/core/store\n",
            "copying build/lib/syft/core/store/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/store\n",
            "copying build/lib/syft/core/store/store_disk.py -> build/bdist.linux-x86_64/egg/syft/core/store\n",
            "copying build/lib/syft/core/store/storeable_object.py -> build/bdist.linux-x86_64/egg/syft/core/store\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/io\n",
            "copying build/lib/syft/core/io/address.py -> build/bdist.linux-x86_64/egg/syft/core/io\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/io/location\n",
            "copying build/lib/syft/core/io/location/location.py -> build/bdist.linux-x86_64/egg/syft/core/io/location\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/io/location/group\n",
            "copying build/lib/syft/core/io/location/group/registry.py -> build/bdist.linux-x86_64/egg/syft/core/io/location/group\n",
            "copying build/lib/syft/core/io/location/group/group.py -> build/bdist.linux-x86_64/egg/syft/core/io/location/group\n",
            "copying build/lib/syft/core/io/location/group/subscription.py -> build/bdist.linux-x86_64/egg/syft/core/io/location/group\n",
            "copying build/lib/syft/core/io/location/group/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/io/location/group\n",
            "copying build/lib/syft/core/io/location/specific.py -> build/bdist.linux-x86_64/egg/syft/core/io/location\n",
            "copying build/lib/syft/core/io/location/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/io/location\n",
            "copying build/lib/syft/core/io/connection.py -> build/bdist.linux-x86_64/egg/syft/core/io\n",
            "copying build/lib/syft/core/io/route.py -> build/bdist.linux-x86_64/egg/syft/core/io\n",
            "copying build/lib/syft/core/io/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/io\n",
            "copying build/lib/syft/core/io/virtual.py -> build/bdist.linux-x86_64/egg/syft/core/io\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/plan\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/plan/translation\n",
            "creating build/bdist.linux-x86_64/egg/syft/core/plan/translation/torchscript\n",
            "copying build/lib/syft/core/plan/translation/torchscript/plan.py -> build/bdist.linux-x86_64/egg/syft/core/plan/translation/torchscript\n",
            "copying build/lib/syft/core/plan/translation/torchscript/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/plan/translation/torchscript\n",
            "copying build/lib/syft/core/plan/translation/torchscript/plan_translate.py -> build/bdist.linux-x86_64/egg/syft/core/plan/translation/torchscript\n",
            "copying build/lib/syft/core/plan/translation/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/plan/translation\n",
            "copying build/lib/syft/core/plan/plan_builder.py -> build/bdist.linux-x86_64/egg/syft/core/plan\n",
            "copying build/lib/syft/core/plan/plan.py -> build/bdist.linux-x86_64/egg/syft/core/plan\n",
            "copying build/lib/syft/core/plan/__init__.py -> build/bdist.linux-x86_64/egg/syft/core/plan\n",
            "copying build/lib/syft/experimental_flags.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/util.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/module.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/callable.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/klass.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/static_attr.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/__init__.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/enum.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/attribute.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/property.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/util.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "copying build/lib/syft/ast/globals.py -> build/bdist.linux-x86_64/egg/syft/ast\n",
            "creating build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/fl_job.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "creating build/bdist.linux-x86_64/egg/syft/federated/model_serialization\n",
            "copying build/lib/syft/federated/model_serialization/state.py -> build/bdist.linux-x86_64/egg/syft/federated/model_serialization\n",
            "copying build/lib/syft/federated/model_serialization/placeholder_id.py -> build/bdist.linux-x86_64/egg/syft/federated/model_serialization\n",
            "copying build/lib/syft/federated/model_serialization/common.py -> build/bdist.linux-x86_64/egg/syft/federated/model_serialization\n",
            "copying build/lib/syft/federated/model_serialization/__init__.py -> build/bdist.linux-x86_64/egg/syft/federated/model_serialization\n",
            "copying build/lib/syft/federated/model_serialization/placeholder.py -> build/bdist.linux-x86_64/egg/syft/federated/model_serialization\n",
            "copying build/lib/syft/federated/fl_client.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/model_centric_fl_worker.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/model_centric_fl_client.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/model_centric_fl_base.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/zksk/secret_pb2.py to secret_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/zksk/nizk_pb2.py to nizk_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/slice_pb2.py to slice_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/set_pb2.py to set_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/list_pb2.py to list_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/tuple_pb2.py to tuple_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/float_pb2.py to float_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/bool_pb2.py to bool_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/collections/ordered_dict_pb2.py to ordered_dict_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/int_pb2.py to int_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/string_pb2.py to string_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/range_pb2.py to range_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/complex_pb2.py to complex_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/none_pb2.py to none_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/python/dict_pb2.py to dict_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/numpy/array_pb2.py to array_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/numpy/tensor_pb2.py to tensor_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/petlib/ecpt_pb2.py to ecpt_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/petlib/bn_pb2.py to bn_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/petlib/ecpt_group_pb2.py to ecpt_group_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/sympc/share_tensor_pb2.py to share_tensor_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/sympc/session_pb2.py to session_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/tenseal/vector_pb2.py to vector_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/statsmodels/family_pb2.py to family_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/statsmodels/results_pb2.py to results_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/sklearn/logistic_model_pb2.py to logistic_model_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/torch/device_pb2.py to device_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/torch/module_pb2.py to module_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/torch/returntypes_pb2.py to returntypes_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/torch/parameter_pb2.py to parameter_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/torch/tensor_pb2.py to tensor_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/pandas/categorical_pb2.py to categorical_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/pandas/series_pb2.py to series_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/lib/pandas/frame_pb2.py to frame_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/service/signaling_service_pb2.py to signaling_service_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/transfer_messages_pb2.py to transfer_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/tensor_messages_pb2.py to tensor_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/association_messages_pb2.py to association_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/infra_messages_pb2.py to infra_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/user_messages_pb2.py to user_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/role_messages_pb2.py to role_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/network_search_messages_pb2.py to network_search_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/dataset_messages_pb2.py to dataset_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/setup_messages_pb2.py to setup_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/request_messages_pb2.py to request_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/grid/messages/group_messages_pb2.py to group_messages_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/util/vendor_bytes_pb2.py to vendor_bytes_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/util/data_message_pb2.py to data_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/remote_dataloader/remote_dataset_pb2.py to remote_dataset_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/common/common_object_pb2.py to common_object_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/auth/signed_message_pb2.py to signed_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service/accept_or_deny_request_message_pb2.py to accept_or_deny_request_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service/get_all_requests_message_pb2.py to get_all_requests_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service/request_answer_response_pb2.py to request_answer_response_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service/request_handler_message_pb2.py to request_handler_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service/request_message_pb2.py to request_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/domain/service/request_answer_message_pb2.py to request_answer_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service/object_search_permission_update_message_pb2.py to object_search_permission_update_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service/get_repr_service_pb2.py to get_repr_service_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service/resolve_pointer_type_service_pb2.py to resolve_pointer_type_service_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service/heritage_update_service_pb2.py to heritage_update_service_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service/repr_service_pb2.py to repr_service_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service/object_search_message_pb2.py to object_search_message_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/service/child_node_lifecycle_service_pb2.py to child_node_lifecycle_service_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/get_set_static_attribute_pb2.py to get_set_static_attribute_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/get_enum_attribute_pb2.py to get_enum_attribute_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/run_class_method_pb2.py to run_class_method_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/save_object_pb2.py to save_object_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/garbage_collect_object_pb2.py to garbage_collect_object_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/action_pb2.py to action_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/get_object_pb2.py to get_object_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/get_set_property_pb2.py to get_set_property_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/garbage_collect_batched_pb2.py to garbage_collect_batched_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/run_function_or_constructor_pb2.py to run_function_or_constructor_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/action/exception_action_pb2.py to exception_action_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/client_pb2.py to client_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/node/common/metadata_pb2.py to metadata_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/pointer/pointer_pb2.py to pointer_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/store/dataset_pb2.py to dataset_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/store/store_object_pb2.py to store_object_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/io/address_pb2.py to address_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/io/location_pb2.py to location_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/io/connection_pb2.py to connection_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/io/route_pb2.py to route_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/proto/core/plan/plan_pb2.py to plan_pb2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generate_wrapper.py to generate_wrapper.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/openmined_psi/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/misc/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/misc/union.py to union.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/pytorch_lightning/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/zksk/nizk.py to nizk.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/zksk/secret.py to secret.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/zksk/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/remote_dataloader/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/bool.py to bool.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/tuple.py to tuple.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/int.py to int.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/set.py to set.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/float.py to float.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/none.py to none.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/complex.py to complex.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/string.py to string.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/primitive_factory.py to primitive_factory.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/list.py to list.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/primitive_interface.py to primitive_interface.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/collections/ordered_dict.py to ordered_dict.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/collections/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/dict.py to dict.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/iterator.py to iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/primitive_container.py to primitive_container.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/types.py to types.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/util.py to util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/range.py to range.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/python/slice.py to slice.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/numpy/array.py to array.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/numpy/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/petlib/ecpt.py to ecpt.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/petlib/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/petlib/ecpt_group.py to ecpt_group.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/petlib/bn.py to bn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/sympc/session_util.py to session_util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/sympc/share.py to share.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/sympc/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/sympc/session.py to session.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tenseal/plain_tensor.py to plain_tensor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tenseal/ckks_vector.py to ckks_vector.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tenseal/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tenseal/context.py to context.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tenseal/bfv_vector.py to bfv_vector.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tenseal/ckks_tensor.py to ckks_tensor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torchvision/allowlist.py to allowlist.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torchvision/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/PIL/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/PIL/image.py to image.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/xgboost/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/pydp/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/statsmodels/results.py to results.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/statsmodels/family.py to family.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/statsmodels/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/opacus/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tensor/tensorbase_util.py to tensorbase_util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tensor/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/tensor/tensorbase.py to tensorbase.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/gym/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/sklearn/serializing_models.py to serializing_models.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/sklearn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/util.py to util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/uppercase_tensor.py to uppercase_tensor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/parameter.py to parameter.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/module.py to module.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/device.py to device.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/allowlist.py to allowlist.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/return_types.py to return_types.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/torch/tensor_util.py to tensor_util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/pandas/series.py to series.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/pandas/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/pandas/categorical_dtype.py to categorical_dtype.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/pandas/categorical.py to categorical.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/pandas/frame.py to frame.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/lib/plan/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/services/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/services/signaling_service.py to signaling_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/example_nodes/network.py to network.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/example_nodes/pks.py to pks.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/example_nodes/device.py to device.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/example_nodes/domain.py to domain.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/connections/webrtc.py to webrtc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/connections/http_connection.py to http_connection.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/connections/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/exceptions.py to exceptions.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/client.py to client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/grid_connection.py to grid_connection.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/enums.py to enums.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/role_api.py to role_api.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/dataset_api.py to dataset_api.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/worker_api.py to worker_api.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/group_api.py to group_api.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/request_api.py to request_api.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/user_api.py to user_api.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/client/request_api/association_api.py to association_api.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/infra_messages.py to infra_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/association_messages.py to association_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/dataset_messages.py to dataset_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/group_messages.py to group_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/tensor_messages.py to tensor_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/network_search_message.py to network_search_message.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/request_messages.py to request_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/transfer_messages.py to transfer_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/role_messages.py to role_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/setup_messages.py to setup_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/messages/user_messages.py to user_messages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/duet/bcolors.py to bcolors.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/duet/signaling_client.py to signaling_client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/duet/webrtc_duet.py to webrtc_duet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/duet/exchange_ids.py to exchange_ids.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/duet/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/duet/om_signaling_client.py to om_signaling_client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid/duet/ui.py to ui.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/logger.py to logger.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/remote_dataloader/remote_dataloader.py to remote_dataloader.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/remote_dataloader/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/object.py to object.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/group.py to group.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/environment.py to environment.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/uid.py to uid.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/message.py to message.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/event_loop.py to event_loop.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/serde/serializable.py to serializable.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/serde/deserialize.py to deserialize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/serde/serialize.py to serialize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/serde/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/pointer.py to pointer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/common/storeable_object.py to storeable_object.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/service/request_answer_message.py to request_answer_message.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/service/request_message.py to request_message.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/service/vm_service.py to vm_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/service/get_all_requests_service.py to get_all_requests_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/service/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/service/request_handler_service.py to request_handler_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/service/accept_or_deny_request_service.py to accept_or_deny_request_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/client.py to client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/domain.py to domain.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/domain/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/pki/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device.py to device.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/client.py to client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs/network.py to network.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs/storage.py to storage.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs/provider.py to provider.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs/gpu.py to gpu.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/specs/cpu.py to cpu.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/unknown.py to unknown.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/device_type.py to device_type.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/device/device_type/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/obj_action_service.py to obj_action_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/child_node_lifecycle_service.py to child_node_lifecycle_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/resolve_pointer_type_service.py to resolve_pointer_type_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/msg_forwarding_service.py to msg_forwarding_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/obj_search_service.py to obj_search_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/heritage_update_service.py to heritage_update_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/node_service.py to node_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/auth.py to auth.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/get_repr_service.py to get_repr_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/repr_service.py to repr_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/obj_search_permission_service.py to obj_search_permission_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/service/solve_pointer_type_service.py to solve_pointer_type_service.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/get_or_set_static_attribute_action.py to get_or_set_static_attribute_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/exception_action.py to exception_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/get_or_set_property_action.py to get_or_set_property_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/common.py to common.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/run_class_method_action.py to run_class_method_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/save_object_action.py to save_object_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/garbage_collect_batched_action.py to garbage_collect_batched_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/function_or_constructor_action.py to function_or_constructor_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/get_object_action.py to get_object_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/garbage_collect_object_action.py to garbage_collect_object_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/action/get_enum_attribute_action.py to get_enum_attribute_action.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/client.py to client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/metadata.py to metadata.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/node.py to node.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/common/util.py to util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/vm/vm.py to vm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/vm/client.py to client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/vm/plan_vm.py to plan_vm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/vm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/abstract/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/abstract/node.py to node.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/network/network.py to network.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/network/client.py to client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/node/network/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection/gc_batched.py to gc_batched.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection/gc_strategy.py to gc_strategy.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection/gc_simple.py to gc_simple.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/pointer/garbage_collection/garbage_collection.py to garbage_collection.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/pointer/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/pointer/pointer.py to pointer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/store/store_interface.py to store_interface.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/store/store_memory.py to store_memory.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/store/dataset.py to dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/store/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/store/store_disk.py to store_disk.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/store/storeable_object.py to storeable_object.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/address.py to address.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/location/location.py to location.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/location/group/registry.py to registry.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/location/group/group.py to group.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/location/group/subscription.py to subscription.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/location/group/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/location/specific.py to specific.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/location/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/connection.py to connection.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/route.py to route.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/io/virtual.py to virtual.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/plan/translation/torchscript/plan.py to plan.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/plan/translation/torchscript/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/plan/translation/torchscript/plan_translate.py to plan_translate.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/plan/translation/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/plan/plan_builder.py to plan_builder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/plan/plan.py to plan.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/core/plan/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/experimental_flags.py to experimental_flags.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/util.py to util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/module.py to module.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/callable.py to callable.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/klass.py to klass.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/static_attr.py to static_attr.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/enum.py to enum.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/attribute.py to attribute.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/property.py to property.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/util.py to util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/ast/globals.py to globals.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/fl_job.py to fl_job.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_serialization/state.py to state.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_serialization/placeholder_id.py to placeholder_id.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_serialization/common.py to common.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_serialization/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_serialization/placeholder.py to placeholder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/fl_client.py to fl_client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_centric_fl_worker.py to model_centric_fl_worker.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_centric_fl_client.py to model_centric_fl_client.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/model_centric_fl_base.py to model_centric_fl_base.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/syft.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/syft.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/syft.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/syft.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/syft.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/syft.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/syft.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "creating 'dist/syft-0.0.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syft-0.0.0-py3.7.egg\n",
            "removing '/usr/local/lib/python3.7/dist-packages/syft-0.0.0-py3.7.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.7/dist-packages/syft-0.0.0-py3.7.egg\n",
            "Extracting syft-0.0.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "syft 0.0.0 is already the active version in easy-install.pth\n",
            "Installing syft-device script to /usr/local/bin\n",
            "Installing syft-domain script to /usr/local/bin\n",
            "Installing syft-network script to /usr/local/bin\n",
            "Installing syft-proto script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/syft-0.0.0-py3.7.egg\n",
            "Processing dependencies for syft==0.0.0\n",
            "\n",
            "\n",
            "An error occurred while building the project, please ensure you have the most updated version of setuptools, setuptools_scm and wheel with:\n",
            "   pip install -U setuptools setuptools_scm wheel\n",
            "\n",
            "\n",
            "error: torch 1.4.0 is installed but torch==1.8.1 is required by {'torchcsprng'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQXFlb55vbi4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e1de2a2-11aa-40e0-ab03-ac25cc884c07"
      },
      "source": [
        "#Runtimeの再起動後に実行\n",
        "#PySyftを0.2.xでバージョン指定しないと以降でエラー\n",
        "!pip install syft==0.2.9\n",
        "import syft as sy\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "#細胞セグメンテーションのレポジトリクローン\n",
        "!git clone https://github.com/CellProfiling/HPA-Cell-Segmentation\n",
        "!cd HPA-Cell-Segmentation; sh install.sh\n",
        "from torchvision import datasets, transforms\n",
        "import pandas as pd\n",
        "from torch.utils import data\n",
        "#学習済みBERTモデルのインストール\n",
        "!pip install pytorch-pretrained-bert\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
        "import pytorch_pretrained_bert\n",
        "\n",
        "nn = torch.nn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft==0.2.9 in /usr/local/lib/python3.7/dist-packages (0.2.9)\n",
            "Requirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.0.2)\n",
            "Requirement already satisfied: numpy~=1.18.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.18.5)\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.1)\n",
            "Requirement already satisfied: shaloop==0.2.1-alpha.11 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.2.1a11)\n",
            "Requirement already satisfied: RestrictedPython~=5.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (5.1)\n",
            "Requirement already satisfied: phe~=1.4.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.0)\n",
            "Requirement already satisfied: requests-toolbelt==0.9.1 in /usr/local/lib/python3.7/dist-packages/requests_toolbelt-0.9.1-py3.7.egg (from syft==0.2.9) (0.9.1)\n",
            "Requirement already satisfied: websockets~=8.1.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (8.1)\n",
            "Requirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.1.4)\n",
            "Requirement already satisfied: tblib~=1.6.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.6.0)\n",
            "Requirement already satisfied: torchvision~=0.5.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.5.0)\n",
            "Collecting Pillow>=7.1.0\n",
            "  Using cached https://files.pythonhosted.org/packages/33/34/542152297dcc6c47a9dcb0685eac6d652d878ed3cea83bf2b23cb988e857/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: syft-proto~=0.5.2 in /usr/local/lib/python3.7/dist-packages/syft_proto-0.5.3-py3.7.egg (from syft==0.2.9) (0.5.3)\n",
            "Requirement already satisfied: importlib-resources~=1.5.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.5.0)\n",
            "Requirement already satisfied: aiortc==0.9.28 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.9.28)\n",
            "Requirement already satisfied: notebook==5.7.8 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (5.7.8)\n",
            "Requirement already satisfied: lz4~=3.0.2 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (3.0.2)\n",
            "Requirement already satisfied: websocket-client~=0.57.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.57.0)\n",
            "Requirement already satisfied: psutil==5.7.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (5.7.0)\n",
            "Requirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (4.5.3)\n",
            "Requirement already satisfied: requests~=2.22.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (2.22.0)\n",
            "Requirement already satisfied: flask-socketio~=4.2.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (4.2.1)\n",
            "Requirement already satisfied: dill~=0.3.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.3.3)\n",
            "Requirement already satisfied: openmined.threepio==0.2.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.2.0)\n",
            "Requirement already satisfied: torch~=1.4.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.0)\n",
            "Requirement already satisfied: cffi>=1 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (1.14.5)\n",
            "Requirement already satisfied: pycparser>=2 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (2.20)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.5.0->syft==0.2.9) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from syft-proto~=0.5.2->syft==0.2.9) (3.12.4)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (4.0.1)\n",
            "Requirement already satisfied: av<9.0.0,>=8.0.0 in /usr/local/lib/python3.7/dist-packages/av-8.0.3-py3.7-linux-x86_64.egg (from aiortc==0.9.28->syft==0.2.9) (8.0.3)\n",
            "Requirement already satisfied: pyee>=6.0.0 in /usr/local/lib/python3.7/dist-packages/pyee-8.1.0-py3.7.egg (from aiortc==0.9.28->syft==0.2.9) (8.1.0)\n",
            "Requirement already satisfied: pylibsrtp>=0.5.6 in /usr/local/lib/python3.7/dist-packages/pylibsrtp-0.6.8-py3.7-linux-x86_64.egg (from aiortc==0.9.28->syft==0.2.9) (0.6.8)\n",
            "Requirement already satisfied: aioice<0.7.0,>=0.6.17 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (0.6.18)\n",
            "Requirement already satisfied: cryptography>=2.2 in /usr/local/lib/python3.7/dist-packages/cryptography-3.4.7-py3.7-linux-x86_64.egg (from aiortc==0.9.28->syft==0.2.9) (3.4.7)\n",
            "Requirement already satisfied: crc32c in /usr/local/lib/python3.7/dist-packages/crc32c-2.2-py3.7-linux-x86_64.egg (from aiortc==0.9.28->syft==0.2.9) (2.2)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.3.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (22.0.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.10.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (1.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.0.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.7.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.10.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.10.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2020.12.5)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2.8)\n",
            "Requirement already satisfied: python-socketio>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from flask-socketio~=4.2.1->syft==0.2.9) (5.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask~=1.1.1->syft==0.2.9) (2.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->syft-proto~=0.5.2->syft==0.2.9) (57.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->importlib-resources~=1.5.0->syft==0.2.9) (3.7.4.3)\n",
            "Requirement already satisfied: netifaces in /usr/local/lib/python3.7/dist-packages/netifaces-0.11.0-py3.7-linux-x86_64.egg (from aioice<0.7.0,>=0.6.17->aiortc==0.9.28->syft==0.2.9) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (2.8.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (1.4.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (2.6.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook==5.7.8->syft==0.2.9) (0.7.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook==5.7.8->syft==0.2.9) (2.6.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook==5.7.8->syft==0.2.9) (5.5.0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft==0.2.9) (0.21.2)\n",
            "Requirement already satisfied: python-engineio>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft==0.2.9) (4.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (20.9)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (1.0.18)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (2.4.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.2.5)\n",
            "\u001b[31mERROR: bokeh 2.3.2 has requirement tornado>=5.1, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 6.2.1\n",
            "    Uninstalling Pillow-6.2.1:\n",
            "      Successfully uninstalled Pillow-6.2.1\n",
            "Successfully installed Pillow-8.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'HPA-Cell-Segmentation' already exists and is not an empty directory.\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.5.2.54)\n",
            "Collecting pillow==6.2.1\n",
            "  Using cached https://files.pythonhosted.org/packages/89/3e/31c2e5385d7588016c6f7ac552e81c3fff2bef4bc61b6f82f8177752405c/Pillow-6.2.1-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "\u001b[31mERROR: syft 0.2.9 has requirement Pillow>=7.1.0, but you'll have pillow 6.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.3.2 has requirement pillow>=7.1.0, but you'll have pillow 6.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.3.2 has requirement tornado>=5.1, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 8.2.0\n",
            "    Uninstalling Pillow-8.2.0:\n",
            "      Successfully uninstalled Pillow-8.2.0\n",
            "Successfully installed pillow-6.2.1\n",
            "Requirement already satisfied: pytorch_zoo from git+https://github.com/haoxusci/pytorch_zoo@master#egg=pytorch_zoo in /usr/local/lib/python3.7/dist-packages (0.0.0)\n",
            "Processing /content/HPA-Cell-Segmentation\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.16.2 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (2.9.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.2.0.32 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (4.5.2.54)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=6.2.1 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (6.2.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pytorch_zoo@ https://github.com/haoxusci/pytorch_zoo/archive/master.zip from https://github.com/haoxusci/pytorch_zoo/archive/master.zip in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (0.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.6.1->hpacellseg==0.1.8) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->hpacellseg==0.1.8) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (4.4.2)\n",
            "Building wheels for collected packages: hpacellseg\n",
            "  Building wheel for hpacellseg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpacellseg: filename=hpacellseg-0.1.8-cp37-none-any.whl size=15465 sha256=5284a96c1a1e22647c98433e2a98baa8928fc3194acacf5b6877598d6886e21d\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/1f/95/9fdc41584d3098d71dca55e74f6c87a5e921bb842cf1874919\n",
            "Successfully built hpacellseg\n",
            "Installing collected packages: hpacellseg\n",
            "  Found existing installation: hpacellseg 0.1.8\n",
            "    Uninstalling hpacellseg-0.1.8:\n",
            "      Successfully uninstalled hpacellseg-0.1.8\n",
            "Successfully installed hpacellseg-0.1.8\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.22.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.17.92)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.92 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.20.92)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.92->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.92->boto3->pytorch-pretrained-bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZOIb-HFcxmV"
      },
      "source": [
        "#仮想ワーカの定義\n",
        "hook = sy.TorchHook(torch)  \n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  \n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  \n",
        "carol = sy.VirtualWorker(hook, id=\"carol\") \n",
        "david = sy.VirtualWorker(hook, id=\"david\") \n",
        "eve = sy.VirtualWorker(hook, id=\"eve\") "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Ev0aJhF5Py"
      },
      "source": [
        "tags = ['BD', 'BP', 'PR', 'SP', 'CH', 'ED']\n",
        "VOCAB_list = ['<PAD>', 'O',]\n",
        "for tag in tags:\n",
        "    VOCAB_list.append('I-'+tag)\n",
        "    VOCAB_list.append('B-'+tag)\n",
        "VOCAB = tuple(VOCAB_list)\n",
        "tag2idx = {tag: idx for idx, tag in enumerate(VOCAB)}\n",
        "idx2tag = {idx: tag for idx, tag in enumerate(VOCAB)}\n",
        "\n",
        "class NerDataset(data.Dataset):\n",
        "    def __init__(self, fpath):\n",
        "        \"\"\"\n",
        "        fpath: [train|valid|test].txt\n",
        "        \"\"\"\n",
        "        entries = open(fpath, 'r').read().strip().split(\"\\n\\n\")\n",
        "        sents, tags_li = [], [] \n",
        "        for entry in entries:\n",
        "            lines = entry.splitlines()\n",
        "            words = [line.split()[0] for line in entry.splitlines() if len(line.split()) > 1]\n",
        "            tags = ([line.split()[-1] for line in entry.splitlines() if len(line.split()) > 1])\n",
        "            if not (len(tags) != 0 and tags.count(tags[0]) == len(tags)):\n",
        "                sents.append([\"[CLS]\"] + words + [\"[SEP]\"])\n",
        "                tags_li.append([\"<PAD>\"] + tags + [\"<PAD>\"])\n",
        "        self.sents, self.tags_li = sents, tags_li\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words, tags = self.sents[idx], self.tags_li[idx] \n",
        "        \n",
        "        x, y = [], [] \n",
        "        is_heads = [] \n",
        "        for w, t in zip(words, tags):\n",
        "            if ord(w[0]) in [65533, 8206, 150, 61656, 128, 157] : \n",
        "                continue \n",
        "            tokens = tokenizer.tokenize(w) if w not in (\"[CLS]\", \"[SEP]\") else [w]\n",
        "            xx = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "            is_head = [1] + [0]*(len(tokens) - 1)\n",
        "\n",
        "            t = [t] + [\"<PAD>\"] * (len(tokens) - 1)  \n",
        "            yy = [tag2idx[each] for each in t]  \n",
        "\n",
        "            x.extend(xx)\n",
        "            is_heads.extend(is_head)\n",
        "            y.extend(yy)\n",
        "        try:\n",
        "          assert len(x)==len(y)==len(is_heads), f\"len(x)={len(x)}, len(y)={len(y)}, len(is_heads)={len(is_heads)}\"\n",
        "        except AssertionError:\n",
        "          print(tags)\n",
        "          for tag in words:\n",
        "              for c in tag:\n",
        "                  print(c, ord(c))\n",
        "          print(words)\n",
        "          print(x)\n",
        "          print(y)\n",
        "          print(is_heads)\n",
        "          raise BaseException(f\"len(x)={len(x)}, len(y)={len(y)}, len(is_heads)={len(is_heads)}\")\n",
        "        \n",
        "        seqlen = len(y)\n",
        "\n",
        "        \n",
        "        words = \" \".join(words)\n",
        "        tags = \" \".join(tags)\n",
        "        return words, x, is_heads, tags, y, seqlen\n",
        "    \n",
        "    def append(self, other):\n",
        "        self.sents.extend(other.sents)\n",
        "        self.tags_li.extend(other.tags_li)\n",
        "\n",
        "def pad(batch):\n",
        "    '''Pads to 50'''\n",
        "    f = lambda x: [sample[x] for sample in batch]\n",
        "    g = lambda x, seqlen: [sample[x] + [\" #!#!\",[0],[0],\" <PAD>\"][x] * (seqlen - len(sample[x])) if len(sample[x]) < seqlen else sample[x][:seqlen] for sample in batch]  \n",
        "    seqlens = f(-1)\n",
        "    maxlen = min(50, np.array(seqlens).max())\n",
        "    words = f(0)\n",
        "    is_heads = g(2, maxlen)\n",
        "    tags = [sample[3] for sample in batch] \n",
        "    g = lambda x, seqlen: [ sample[x] + [0] * (seqlen - len(sample[x])) if len(sample[x]) < seqlen else sample[x][:seqlen] for sample in batch]  # 0: <pad>\n",
        "    x = g(1, maxlen)\n",
        "    y = g(-2, maxlen)\n",
        "    f = torch.LongTensor\n",
        "    return words, f(x), is_heads, tags, f(y), [maxlen for sample in batch]\n",
        "\n",
        "def pad_max(batch):\n",
        "    '''Pads to the longest sample'''\n",
        "    f = lambda x: [sample[x] for sample in batch]\n",
        "    words = f(0)\n",
        "    is_heads = f(2)\n",
        "    tags = f(3)\n",
        "    seqlens = f(-1)\n",
        "    maxlen = np.array(seqlens).max()\n",
        "\n",
        "    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] \n",
        "    x = f(1, maxlen)\n",
        "    y = f(-2, maxlen)\n",
        "    f = torch.LongTensor\n",
        "    return words, f(x), is_heads, tags, f(y), seqlens\n",
        "\n",
        "def pad_fed(batch):\n",
        "    '''Pads always to 50 since there will be a fixed size in the embedding layer'''\n",
        "    f = lambda x: [sample[x] for sample in batch]\n",
        "    g = lambda x, seqlen: [sample[x] + [\" #!#!\",[0],[0],\" <PAD>\"][x] * (seqlen - len(sample[x])) if len(sample[x]) < seqlen else sample[x][:seqlen] for sample in batch]  \n",
        "    seqlens = f(-1)\n",
        "    maxlen = 50\n",
        "    words = f(0)\n",
        "    is_heads = g(2, maxlen)\n",
        "    tags = [sample[3] for sample in batch] \n",
        "    g = lambda x, seqlen: [ sample[x] + [0] * (seqlen - len(sample[x])) if len(sample[x]) < seqlen else sample[x][:seqlen] for sample in batch]  # 0: <pad>\n",
        "\n",
        "    x = g(1, maxlen)\n",
        "    y = g(-2, maxlen)\n",
        "\n",
        "    f = torch.LongTensor\n",
        "    return words, f(x), is_heads, tags, f(y), [maxlen for sample in batch]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lG1cWaZSM2o"
      },
      "source": [
        "## 学習済みBERTモデルのロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAFb5ZCHn6GN"
      },
      "source": [
        "\"\"\"PyTorch BERT model.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import tempfile\n",
        "import sys\n",
        "from io import open\n",
        "\n",
        "# import torch\n",
        "# from torch import nn\n",
        "# from torch.nn import CrossEntropyLoss\n",
        "# import pytorch_pretrained_bert\n",
        "from pytorch_pretrained_bert.file_utils import cached_path, WEIGHTS_NAME, CONFIG_NAME\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "PRETRAINED_MODEL_ARCHIVE_MAP = {\n",
        "    'bert-base-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\",\n",
        "    'bert-large-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz\",\n",
        "    'bert-base-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz\",\n",
        "    'bert-large-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz\",\n",
        "    'bert-base-multilingual-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz\",\n",
        "    'bert-base-multilingual-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz\",\n",
        "    'bert-base-chinese': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz\",\n",
        "}\n",
        "BERT_CONFIG_NAME = 'bert_config.json'\n",
        "TF_WEIGHTS_NAME = 'model.ckpt'\n",
        "\n",
        "def load_tf_weights_in_bert(model, tf_checkpoint_path):\n",
        "    \"\"\" Load tf checkpoints in a pytorch model\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import re\n",
        "        import numpy as np\n",
        "        import tensorflow as tf\n",
        "    except ImportError:\n",
        "        print(\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"\n",
        "            \"https://www.tensorflow.org/install/ for installation instructions.\")\n",
        "        raise\n",
        "    tf_path = os.path.abspath(tf_checkpoint_path)\n",
        "    print(\"Converting TensorFlow checkpoint from {}\".format(tf_path))\n",
        "    # TFモデルの重み\n",
        "    init_vars = tf.train.list_variables(tf_path)\n",
        "    names = []\n",
        "    arrays = []\n",
        "    for name, shape in init_vars:\n",
        "        print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
        "        array = tf.train.load_variable(tf_path, name)\n",
        "        names.append(name)\n",
        "        arrays.append(array)\n",
        "\n",
        "    for name, array in zip(names, arrays):\n",
        "        name = name.split('/')\n",
        "        if any(n in [\"adam_v\", \"adam_m\", \"global_step\"] for n in name):\n",
        "            print(\"Skipping {}\".format(\"/\".join(name)))\n",
        "            continue\n",
        "        pointer = model\n",
        "        for m_name in name:\n",
        "            if re.fullmatch(r'[A-Za-z]+_\\d+', m_name):\n",
        "                l = re.split(r'_(\\d+)', m_name)\n",
        "            else:\n",
        "                l = [m_name]\n",
        "            if l[0] == 'kernel' or l[0] == 'gamma':\n",
        "                pointer = getattr(pointer, 'weight')\n",
        "            elif l[0] == 'output_bias' or l[0] == 'beta':\n",
        "                pointer = getattr(pointer, 'bias')\n",
        "            elif l[0] == 'output_weights':\n",
        "                pointer = getattr(pointer, 'weight')\n",
        "            elif l[0] == 'squad':\n",
        "                pointer = getattr(pointer, 'classifier')\n",
        "            else:\n",
        "                try:\n",
        "                    pointer = getattr(pointer, l[0])\n",
        "                except AttributeError:\n",
        "                    print(\"Skipping {}\".format(\"/\".join(name)))\n",
        "                    continue\n",
        "            if len(l) >= 2:\n",
        "                num = int(l[1])\n",
        "                pointer = pointer[num]\n",
        "        if m_name[-11:] == '_embeddings':\n",
        "            pointer = getattr(pointer, 'weight')\n",
        "        elif m_name == 'kernel':\n",
        "            array = np.transpose(array)\n",
        "        try:\n",
        "            assert pointer.shape == array.shape\n",
        "        except AssertionError as e:\n",
        "            e.args += (pointer.shape, array.shape)\n",
        "            raise\n",
        "        print(\"Initialize PyTorch weight {}\".format(name))\n",
        "        pointer.data = torch.from_numpy(array)\n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"Implementation of the gelu activation function.\n",
        "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
        "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "        Also see https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
        "\n",
        "\n",
        "class BertConfig(object):\n",
        "    \"\"\"Configuration class to store the configuration of a `BertModel`.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size_or_config_json_file,\n",
        "                 hidden_size=768,\n",
        "                 num_hidden_layers=12,\n",
        "                 num_attention_heads=12,\n",
        "                 intermediate_size=3072,\n",
        "                 hidden_act=\"gelu\",\n",
        "                 hidden_dropout_prob=0.1,\n",
        "                 attention_probs_dropout_prob=0.1,\n",
        "                 max_position_embeddings=512,\n",
        "                 type_vocab_size=2,\n",
        "                 initializer_range=0.02):\n",
        "        \"\"\"Constructs BertConfig.\n",
        "\n",
        "        Args:\n",
        "            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n",
        "            hidden_size: Size of the encoder layers and the pooler layer.\n",
        "            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n",
        "            num_attention_heads: Number of attention heads for each attention layer in\n",
        "                the Transformer encoder.\n",
        "            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n",
        "                layer in the Transformer encoder.\n",
        "            hidden_act: The non-linear activation function (function or string) in the\n",
        "                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n",
        "            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n",
        "                layers in the embeddings, encoder, and pooler.\n",
        "            attention_probs_dropout_prob: The dropout ratio for the attention\n",
        "                probabilities.\n",
        "            max_position_embeddings: The maximum sequence length that this model might\n",
        "                ever be used with. Typically set this to something large just in case\n",
        "                (e.g., 512 or 1024 or 2048).\n",
        "            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n",
        "                `BertModel`.\n",
        "            initializer_range: The sttdev of the truncated_normal_initializer for\n",
        "                initializing all weight matrices.\n",
        "        \"\"\"\n",
        "        if isinstance(vocab_size_or_config_json_file, str) or (sys.version_info[0] == 2\n",
        "                        and isinstance(vocab_size_or_config_json_file, unicode)):\n",
        "            with open(vocab_size_or_config_json_file, \"r\", encoding='utf-8') as reader:\n",
        "                json_config = json.loads(reader.read())\n",
        "            for key, value in json_config.items():\n",
        "                self.__dict__[key] = value\n",
        "        elif isinstance(vocab_size_or_config_json_file, int):\n",
        "            self.vocab_size = vocab_size_or_config_json_file\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_hidden_layers = num_hidden_layers\n",
        "            self.num_attention_heads = num_attention_heads\n",
        "            self.hidden_act = hidden_act\n",
        "            self.intermediate_size = intermediate_size\n",
        "            self.hidden_dropout_prob = hidden_dropout_prob\n",
        "            self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "            self.max_position_embeddings = max_position_embeddings\n",
        "            self.type_vocab_size = type_vocab_size\n",
        "            self.initializer_range = initializer_range\n",
        "        else:\n",
        "            raise ValueError(\"First argument must be either a vocabulary size (int)\"\n",
        "                             \"or the path to a pretrained model config file (str)\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, json_object):\n",
        "        \"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"\n",
        "        config = BertConfig(vocab_size_or_config_json_file=-1)\n",
        "        for key, value in json_object.items():\n",
        "            config.__dict__[key] = value\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_json_file(cls, json_file):\n",
        "        \"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"\n",
        "        with open(json_file, \"r\", encoding='utf-8') as reader:\n",
        "            text = reader.read()\n",
        "        return cls.from_dict(json.loads(text))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "    def to_json_file(self, json_file_path):\n",
        "        \"\"\" Save this instance to a json file.\"\"\"\n",
        "        with open(json_file_path, \"w\", encoding='utf-8') as writer:\n",
        "            writer.write(self.to_json_string())\n",
        "\n",
        "try:\n",
        "    from apex.normalization.fused_layer_norm import FusedLayerNorm as BertLayerNorm\n",
        "except ImportError:\n",
        "    logger.info(\"Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\")\n",
        "    class BertLayerNorm(nn.Module):\n",
        "        def __init__(self, hidden_size, eps=1e-12):\n",
        "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "            \"\"\"\n",
        "            super(BertLayerNorm, self).__init__()\n",
        "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "            self.variance_epsilon = eps\n",
        "\n",
        "        def forward(self, x):\n",
        "            u = x.mean(-1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "            return self.weight * x + self.bias\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.register_buffer('position_ids', torch.arange(50, dtype=torch.long, device='cuda').unsqueeze(0).expand(torch.Size([128, 50])))\n",
        "        self.register_buffer('token_type_ids', torch.zeros(torch.Size([128, 50]), dtype=torch.long, device='cuda'))\n",
        "        \n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(self.position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(self.token_type_ids) \n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfAttention, self).__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads) \n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size  \n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        x = x.view(128, 50, 12, 64)\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        return x\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)        \n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        loc = context_layer.location\n",
        "        context_layer = context_layer.get()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        context_layer = context_layer.send(loc)\n",
        "        return context_layer\n",
        "\n",
        "\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config):  \n",
        "        super(BertSelfOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertAttention, self).__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask):\n",
        "        self_output = self.self(input_tensor, attention_mask)\n",
        "        attention_output = self.output(self_output, input_tensor)\n",
        "        return attention_output\n",
        "\n",
        "\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertIntermediate, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str) or (sys.version_info[0] == 2 and isinstance(config.hidden_act, unicode)):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertLayer, self).__init__()\n",
        "        self.attention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        attention_output = self.attention(hidden_states, attention_mask)\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output\n",
        "\n",
        "\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertEncoder, self).__init__()\n",
        "        layer = BertLayer(config)\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
        "        all_encoder_layers = []\n",
        "        for layer_module in self.layer:\n",
        "            hidden_states = layer_module(hidden_states, attention_mask)\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append(hidden_states)\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append(hidden_states)\n",
        "        return all_encoder_layers\n",
        "\n",
        "\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertPooler, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "class BertPredictionHeadTransform(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertPredictionHeadTransform, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        if isinstance(config.hidden_act, str) or (sys.version_info[0] == 2 and isinstance(config.hidden_act, unicode)):\n",
        "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.transform_act_fn = config.hidden_act\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.transform_act_fn(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertLMPredictionHead(nn.Module):\n",
        "    def __init__(self, config, bert_model_embedding_weights):\n",
        "        super(BertLMPredictionHead, self).__init__()\n",
        "        self.transform = BertPredictionHeadTransform(config)\n",
        "\n",
        "        self.decoder = nn.Linear(bert_model_embedding_weights.size(1),\n",
        "                                 bert_model_embedding_weights.size(0),\n",
        "                                 bias=False)\n",
        "        self.decoder.weight = bert_model_embedding_weights\n",
        "        self.bias = nn.Parameter(torch.zeros(bert_model_embedding_weights.size(0)))\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.transform(hidden_states)\n",
        "        hidden_states = self.decoder(hidden_states) + self.bias\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertOnlyMLMHead(nn.Module):\n",
        "    def __init__(self, config, bert_model_embedding_weights):\n",
        "        super(BertOnlyMLMHead, self).__init__()\n",
        "        self.predictions = BertLMPredictionHead(config, bert_model_embedding_weights)\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        return prediction_scores\n",
        "\n",
        "\n",
        "class BertOnlyNSPHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertOnlyNSPHead, self).__init__()\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, pooled_output):\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
        "        return seq_relationship_score\n",
        "\n",
        "\n",
        "class BertPreTrainingHeads(nn.Module):\n",
        "    def __init__(self, config, bert_model_embedding_weights):\n",
        "        super(BertPreTrainingHeads, self).__init__()\n",
        "        self.predictions = BertLMPredictionHead(config, bert_model_embedding_weights)\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, sequence_output, pooled_output):\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
        "        return prediction_scores, seq_relationship_score\n",
        "\n",
        "class BertPreTrainedModel(nn.Module):\n",
        "    \"\"\" An abstract class to handle weights initialization and\n",
        "        a simple interface for dowloading and loading pretrained models.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super(BertPreTrainedModel, self).__init__()\n",
        "        if not isinstance(config, BertConfig):\n",
        "            raise ValueError(\n",
        "                \"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"\n",
        "                \"To create a model from a Google pretrained model use \"\n",
        "                \"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(\n",
        "                    self.__class__.__name__, self.__class__.__name__\n",
        "                ))\n",
        "        self.config = config\n",
        "\n",
        "    def init_bert_weights(self, module):\n",
        "        \"\"\" Initialize the weights.\n",
        "        \"\"\"\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, BertLayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n",
        "        \"\"\"\n",
        "        Instantiate a BertPreTrainedModel from a pre-trained model file or a pytorch state dict.\n",
        "        Download and cache the pre-trained model file if needed.\n",
        "\n",
        "        Params:\n",
        "            pretrained_model_name_or_path: either:\n",
        "                - a str with the name of a pre-trained model to load selected in the list of:\n",
        "                    . `bert-base-uncased`\n",
        "                    . `bert-large-uncased`\n",
        "                    . `bert-base-cased`\n",
        "                    . `bert-large-cased`\n",
        "                    . `bert-base-multilingual-uncased`\n",
        "                    . `bert-base-multilingual-cased`\n",
        "                    . `bert-base-chinese`\n",
        "                - a path or url to a pretrained model archive containing:\n",
        "                    . `bert_config.json` a configuration file for the model\n",
        "                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n",
        "                - a path or url to a pretrained model archive containing:\n",
        "                    . `bert_config.json` a configuration file for the model\n",
        "                    . `model.chkpt` a TensorFlow checkpoint\n",
        "            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n",
        "            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n",
        "            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models\n",
        "            *inputs, **kwargs: additional input for the specific Bert class\n",
        "                (ex: num_labels for BertForSequenceClassification)\n",
        "        \"\"\"\n",
        "        state_dict = kwargs.get('state_dict', None)\n",
        "        kwargs.pop('state_dict', None)\n",
        "        cache_dir = kwargs.get('cache_dir', None)\n",
        "        kwargs.pop('cache_dir', None)\n",
        "        from_tf = kwargs.get('from_tf', False)\n",
        "        kwargs.pop('from_tf', None)\n",
        "\n",
        "        if pretrained_model_name_or_path in PRETRAINED_MODEL_ARCHIVE_MAP:\n",
        "            archive_file = PRETRAINED_MODEL_ARCHIVE_MAP[pretrained_model_name_or_path]\n",
        "        else:\n",
        "            archive_file = pretrained_model_name_or_path\n",
        "\n",
        "        try:\n",
        "            resolved_archive_file = cached_path(archive_file, cache_dir=cache_dir)\n",
        "        except EnvironmentError:\n",
        "            logger.error(\n",
        "                \"Model name '{}' was not found in model name list ({}). \"\n",
        "                \"We assumed '{}' was a path or url but couldn't find any file \"\n",
        "                \"associated to this path or url.\".format(\n",
        "                    pretrained_model_name_or_path,\n",
        "                    ', '.join(PRETRAINED_MODEL_ARCHIVE_MAP.keys()),\n",
        "                    archive_file))\n",
        "            return None\n",
        "        if resolved_archive_file == archive_file:\n",
        "            logger.info(\"loading archive file {}\".format(archive_file))\n",
        "        else:\n",
        "            logger.info(\"loading archive file {} from cache at {}\".format(\n",
        "                archive_file, resolved_archive_file))\n",
        "        tempdir = None\n",
        "        if os.path.isdir(resolved_archive_file) or from_tf:\n",
        "            serialization_dir = resolved_archive_file\n",
        "        else:\n",
        "\n",
        "            tempdir = tempfile.mkdtemp()\n",
        "            logger.info(\"extracting archive file {} to temp dir {}\".format(\n",
        "                resolved_archive_file, tempdir))\n",
        "            with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
        "                archive.extractall(tempdir)\n",
        "            serialization_dir = tempdir\n",
        "\n",
        "        config_file = os.path.join(serialization_dir, CONFIG_NAME)\n",
        "        if not os.path.exists(config_file):\n",
        "\n",
        "            config_file = os.path.join(serialization_dir, BERT_CONFIG_NAME)\n",
        "        config = BertConfig.from_json_file(config_file)\n",
        "        logger.info(\"Model config {}\".format(config))\n",
        "\n",
        "        model = cls(config, *inputs, **kwargs)\n",
        "        if state_dict is None and not from_tf:\n",
        "            weights_path = os.path.join(serialization_dir, WEIGHTS_NAME)\n",
        "            state_dict = torch.load(weights_path, map_location='cpu')\n",
        "        if tempdir:\n",
        "\n",
        "            shutil.rmtree(tempdir)\n",
        "        if from_tf:\n",
        "\n",
        "            weights_path = os.path.join(serialization_dir, TF_WEIGHTS_NAME)\n",
        "            return load_tf_weights_in_bert(model, weights_path)\n",
        "\n",
        "        old_keys = []\n",
        "        new_keys = []\n",
        "        for key in state_dict.keys():\n",
        "            new_key = None\n",
        "            if 'gamma' in key:\n",
        "                new_key = key.replace('gamma', 'weight')\n",
        "            if 'beta' in key:\n",
        "                new_key = key.replace('beta', 'bias')\n",
        "            if new_key:\n",
        "                old_keys.append(key)\n",
        "                new_keys.append(new_key)\n",
        "        for old_key, new_key in zip(old_keys, new_keys):\n",
        "            state_dict[new_key] = state_dict.pop(old_key)\n",
        "\n",
        "        missing_keys = []\n",
        "        unexpected_keys = []\n",
        "        error_msgs = []\n",
        "\n",
        "        metadata = getattr(state_dict, '_metadata', None)\n",
        "        state_dict = state_dict.copy()\n",
        "        if metadata is not None:\n",
        "            state_dict._metadata = metadata\n",
        "\n",
        "        def load(module, prefix=''):\n",
        "            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
        "            module._load_from_state_dict(\n",
        "                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
        "            for name, child in module._modules.items():\n",
        "                if child is not None:\n",
        "                    load(child, prefix + name + '.')\n",
        "        start_prefix = ''\n",
        "        if not hasattr(model, 'bert') and any(s.startswith('bert.') for s in state_dict.keys()):\n",
        "            start_prefix = 'bert.'\n",
        "        load(model, prefix=start_prefix)\n",
        "        if len(missing_keys) > 0:\n",
        "            logger.info(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
        "                model.__class__.__name__, missing_keys))\n",
        "        if len(unexpected_keys) > 0:\n",
        "            logger.info(\"Weights from pretrained model not used in {}: {}\".format(\n",
        "                model.__class__.__name__, unexpected_keys))\n",
        "        if len(error_msgs) > 0:\n",
        "            raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
        "                               model.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
        "        return model\n",
        "\n",
        "\n",
        "class BertModel(BertPreTrainedModel):\n",
        "    \"\"\"BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "\n",
        "    Params:\n",
        "        config: a BertConfig class instance with the configuration to build a new model\n",
        "\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "\n",
        "    Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "        `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "            - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "                of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "                encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "            - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "                to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "        `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "            classifier pretrained on top of the hidden state associated to the first character of the\n",
        "            input (`CLS`) to train on the Next-Sentence task (see BERT's paper).\n",
        "\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "\n",
        "    config = modeling.BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "\n",
        "    model = modeling.BertModel(config=config)\n",
        "    all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertModel, self).__init__(config)\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "        self.apply(self.init_bert_weights)\n",
        "        extended_attention_mask = torch.ones(torch.Size([128, 1, 1, 50])).to('cuda')\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        self.register_buffer('extended_attention_mask', extended_attention_mask)\n",
        "\n",
        "        print('this is the model implemeted on the nb')\n",
        "          \n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True):\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        embedding_output = self.embeddings(input_ids)\n",
        "        encoded_layers = self.encoder(embedding_output,\n",
        "                                      self.extended_attention_mask,\n",
        "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
        "        sequence_output = encoded_layers[-1]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        if not output_all_encoded_layers:\n",
        "            encoded_layers = encoded_layers[-1]\n",
        "        return encoded_layers, pooled_output\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnKZh68zF5SR"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, top_rnns=False, vocab_size=None, device='cpu', finetuning=False):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "        self.top_rnns=top_rnns\n",
        "        if top_rnns:\n",
        "            self.rnn = nn.LSTM(bidirectional=True, num_layers=2, input_size=768, hidden_size=768//2, batch_first=True)\n",
        "        self.fc = nn.Linear(768, vocab_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.finetuning = finetuning\n",
        "\n",
        "    def forward(self, x, y, ):\n",
        "        '''\n",
        "        x: (N, T). int64\n",
        "        y: (N, T). int64\n",
        "        Returns\n",
        "        enc: (N, T, VOCAB)\n",
        "        '''\n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        if self.training and self.finetuning:\n",
        "  \n",
        "            self.bert.train()\n",
        "           \n",
        "            encoded_layers, _ = self.bert(x)\n",
        "            enc = encoded_layers[-1]\n",
        "          \n",
        "        else:\n",
        "            self.bert.eval()\n",
        "            with torch.no_grad():\n",
        "                encoded_layers, _ = self.bert(x)\n",
        "                enc = encoded_layers[-1]\n",
        "\n",
        "        if self.top_rnns:\n",
        "            enc, _ = self.rnn(enc)\n",
        "        logits = self.fc(enc)\n",
        "        y_hat = logits.argmax(-1)\n",
        "        return logits, y, y_hat"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMh_ApScra5T"
      },
      "source": [
        "### ここでデータの前処理をしておかないと詰む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acL2OzyNpArT"
      },
      "source": [
        "paths_annot = sorted([os.path.join(f[0], name) for f in os.walk('./dataset_txt') \n",
        "                if len(f[2])!=0 for name in f[2] if os.path.splitext(name)[-1] == '.txt' and name.split('_')[0]=='annot'],\n",
        "               key=lambda path: int(path.split('_')[-1].split('.')[0]))\n",
        "training_files = [path for path in paths_annot if 'training' in path.split('/')]\n",
        "eval_files = [path for path in paths_annot if 'eval' in path.split('/')]\n",
        "test_files = [path for path in paths_annot if 'test' in path.split('/')]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INJK415_emDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae503a80-45cc-4dd0-f500-6ce589968b4a"
      },
      "source": [
        "eval_dataset = NerDataset(eval_files[0])\n",
        "_ = [eval_dataset.append(NerDataset(eval_file)) for eval_file in eval_files[1:]]\n",
        "\n",
        "test_dataset = NerDataset(test_files[0])\n",
        "_ = [test_dataset.append(NerDataset(test_file)) for test_file in test_files[1:]]\n",
        "\n",
        "eval_iter = data.DataLoader(dataset=eval_dataset,\n",
        "                              batch_size=1,\n",
        "                              shuffle=True,\n",
        "                              num_workers=16,\n",
        "                              collate_fn=pad)\n",
        "test_iter = data.DataLoader(dataset=test_dataset,\n",
        "                              batch_size=32,\n",
        "                              shuffle=True,\n",
        "                              num_workers=16,\n",
        "                              collate_fn=pad)\n",
        "print(len(eval_iter))\n",
        "print(len(test_iter))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12267\n",
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjF9fet1G7N9"
      },
      "source": [
        "### 連合学習のtrain定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUgSDE_AJqRb"
      },
      "source": [
        "def federated_train(model, device, iterator, criterion):\n",
        "    model.train()\n",
        "    loc = ''\n",
        "    for i, batch in enumerate(iterator):\n",
        "    \n",
        "        x, y = batch\n",
        "        if loc != x.location:\n",
        "            print(f'data location {x.location}')\n",
        "            if model.location != None:\n",
        "                model.get()\n",
        "            model.send(x.location) \n",
        "            optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "            loc = x.location\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        _y = y \n",
        "        optimizer.zero_grad()\n",
        "        logits, y, _ = model(x, y) \n",
        "        logits = logits.view(-1, len(VOCAB_list)) \n",
        "        y = y.view(-1)  \n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i%10==0: \n",
        "            print(f\"step: {i}, loss: {loss.get().item()}\")\n",
        "    model.get() "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8hpX44WLC3L"
      },
      "source": [
        "学習のためにモデルをよみこんでおく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxrHwSyPlqIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e08565-3c08-4c91-e735-6bbee9637d9c"
      },
      "source": [
        "print(torch.cuda.max_memory_allocated(device=None))\n",
        "lr = 0.0001\n",
        "finetuning = True\n",
        "top_rnns = False\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Net(top_rnns=top_rnns, vocab_size=len(VOCAB), device=device, finetuning=finetuning).to(device)\n",
        "print(torch.cuda.max_memory_allocated(device=None))\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "this is the model implemeted on the nb\n",
            "433886208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jggSzl1Nf6oM"
      },
      "source": [
        " ## Distributing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBv4x3ZjIXPx"
      },
      "source": [
        "import math\n",
        "def dataset_federate(dataset, workers):\n",
        "    \"\"\"\n",
        "    Add a method to easily transform a torch.Dataset or a sy.BaseDataset\n",
        "    into a sy.FederatedDataset. The dataset given is split in len(workers)\n",
        "    part and sent to each workers\n",
        "    \"\"\"\n",
        "    data_size = math.ceil(len(dataset) / len(workers))\n",
        "    datasets = []\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=data_size, collate_fn=pad_fed)\n",
        "    for dataset_idx, (words, x, is_heads, tags, y, seqlen) in enumerate(data_loader):\n",
        "        worker = workers[dataset_idx % len(workers)]\n",
        "        data_batches = x.size(0)//128\n",
        "        x =  x.narrow(0, 0, int(data_batches*128))        \n",
        "        y =  y.narrow(0, 0, int(data_batches*128))        \n",
        "        data = x.send(worker)\n",
        "        targets = y.send(worker)\n",
        "        datasets.append(sy.BaseDataset(data, targets)) \n",
        "    return sy.FederatedDataset(datasets)\n",
        "NerDataset.federate = dataset_federate"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzE3TyLUgCOZ"
      },
      "source": [
        "train_dataset = NerDataset(training_files[0])\n",
        "_ = [train_dataset.append(NerDataset(train_file)) for train_file in training_files[1:200]]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz7P3OVdLz35"
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader(train_dataset.federate((bob, alice, carol, david, eve)),\n",
        "                              batch_size=128,\n",
        "                              shuffle=True)\n",
        "federated_train_iter = federated_train_loader"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QurWsl_yFZQe"
      },
      "source": [
        "## Federated training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgJ4XQGaFYpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b312a24c-6a9b-4a1e-e8cc-c7bc224bdb16"
      },
      "source": [
        "#experiment_code\n",
        "for epoch in range(1, 50):\n",
        "    federated_train(model, device, federated_train_iter, criterion)\n",
        "    print(f\"=========eval at epoch={epoch}=========\")\n",
        "print(torch.cuda.max_memory_allocated(device=None))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0992908701300621\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:260>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=1=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.08275872468948364\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:260>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=2=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.07239018380641937\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=3=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.062081970274448395\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=4=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.05889151990413666\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=5=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.04374416172504425\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=6=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.030117738991975784\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=7=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.026916207745671272\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=8=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.023318961262702942\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:260>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=9=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.01594037376344204\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:260>\n",
            "=========eval at epoch=10=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.013336678966879845\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:260>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=11=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.008330190554261208\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=12=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.009813682176172733\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=13=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.03105713427066803\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=14=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.013809774070978165\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=15=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.009966136887669563\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=16=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.00403837114572525\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=17=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0029844508972018957\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=18=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0063249110244214535\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=19=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.013299237936735153\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=20=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0035860033240169287\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=21=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.004039369523525238\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=22=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.010838131420314312\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=23=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.002288529882207513\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=24=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.002815793501213193\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=25=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.003979670815169811\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=26=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.007757955696433783\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=27=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.006116881966590881\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=28=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.004338264465332031\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=29=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0006793664069846272\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:260>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=30=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0031039277091622353\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=31=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0005784376407973468\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=32=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.011806023307144642\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=33=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0011436525965109468\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=34=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0015304534463211894\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=35=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0020392867736518383\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=36=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0003710727614816278\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=37=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0019669928587973118\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=38=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0022940440103411674\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=39=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.003612370928749442\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:260>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=40=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0014264665078371763\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=41=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 8.876610809238628e-05\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=42=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.004221026785671711\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=43=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0008900168468244374\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=44=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.008239451795816422\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=45=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0033665981609374285\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=46=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.006022349931299686\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=47=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.0034201035741716623\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=48=========\n",
            "data location <VirtualWorker id:bob #objects:4>\n",
            "step: 0, loss: 0.004865687340497971\n",
            "data location <VirtualWorker id:alice #objects:4>\n",
            "data location <VirtualWorker id:carol #objects:4>\n",
            "data location <VirtualWorker id:david #objects:4>\n",
            "data location <VirtualWorker id:eve #objects:4>\n",
            "=========eval at epoch=49=========\n",
            "8711152640\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
